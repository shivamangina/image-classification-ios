{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a1b195-9cf2-472b-a560-3b6a89bf1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the https://www.kaggle.com/datasets/andrewmvd/animal-faces using opendatasets\n",
    "# import torch, torchvision, transforms, dataloader and dataset from utils ,  label encode\n",
    "# matplotlib., PIL, pandas, numpy,os Label Encoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951241d6-3910-4a0f-8306-0d9f36dba79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if possible                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1dc8d29-0dd4-4b8c-991a-4e4d324c7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  read all the data from train and val\n",
    "#  create a dataframe and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd28575-516f-4f6e-b8c9-6a1628030d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split the train ,test data set into into 0.7 and 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf7c3e7-84ee-46c7-94b6-70d4e57fe387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  transforms.compose\n",
    "    # resize\n",
    "    #  totensor\n",
    "    #  convertImgeDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f3cb0d-1342-4fcd-8f9b-03659b2893ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create customImageDataset class\n",
    "    # dataframe\n",
    "    # transform\n",
    "    # labels\n",
    "    # __len__\n",
    "    # __getitem_\n",
    "    #  transform\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b273be-e58a-4e89-b19c-87eca8bb0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train, val and test dataset with the customImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e45ac95-4a72-4439-9fe0-e91964e37705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 9*9 grid of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e48c53-270f-48b7-a551-9958670102a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learningRate\n",
    "# batchsize\n",
    "# epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2603ec06-392f-4f96-8528-a90cf29711d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a nn class\n",
    " # __init__\n",
    " # conv1 --> nn.Conv2d convolutionsal layer\n",
    " #  conv2 --> same\n",
    " #  conv3\n",
    " # pooling \n",
    " #  relu\n",
    " #  flatten \n",
    " # linear\n",
    " # linear output\n",
    "\n",
    "# forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f7dfe2a-fb20-452c-b94a-7b7daf50cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fdca1ab-7589-44ca-841e-c52b6969a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion\n",
    "#  optimizer\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf6f5c2-4d19-41e0-9c47-dab99db76621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calculate loss and accuracy of the train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a773ace-9bea-4f5e-8157-6184a98cfab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51ecba7-a995-49da-bdce-5059d886e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d1cc1-67df-4739-b745-ce5fa14e5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  draw the accuracy, loss  graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e254f202-87e4-474f-97de-a49a733e1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model - predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417a44d-7961-4cee-8c39-d221d8415825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8ac1e-b0bc-4161-a9c3-57a7032e60f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
