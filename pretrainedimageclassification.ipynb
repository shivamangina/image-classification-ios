{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a542098b-51e0-4c76-b1cc-347fc677af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "# Bean leaf classification\n",
    "\n",
    "# import the opendata sets and get the kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb42ac7c-6cb7-48ca-a736-16be0b07b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch, nn optimizor, torchvision, transformations\n",
    "#  data loader, dataset, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b1e896-19af-493c-af31-7de97b001ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use Googlenet or ALexnet using and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedad8c2-45bc-4968-a66f-bc6375ed8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gpu is present use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44194f9b-332c-42f1-a684-3ad865f06d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load the train and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee366d48-a305-4192-9aea-3a77b411c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the the first 5 lines\n",
    "#  print the shape of the train and val shape\n",
    "#  get the unique categories and value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b128d1a-3c75-449c-ab17-f952407c362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  transform compose\n",
    " # Resize\n",
    " # to tensor\n",
    " # convertImageDtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99247f7-1a57-4ba4-ae39-06f2fcd8e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create customdataset class\n",
    "# dataframe\n",
    "# transform\n",
    "# labels\n",
    "# __getitem__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be2ef16-2bf5-4bd5-bfa3-eef882b8998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_dataset\n",
    "# create val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b448711c-9bba-4229-8c6f-35574ac905f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 9*9 grid of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aad3223-28dc-40be-ae98-2491f8c05fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use google net model\n",
    "# train using google net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "108ea5f4-fea9-4433-a351-25100dd08727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calculate loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750b0cff-d01a-41ea-95a0-1bc376775052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph and accuracy of the googlenet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4790aec-50a1-487f-93ed-431b3217f42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
